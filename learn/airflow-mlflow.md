---
title: "Use Apache Kafka with Apache Airflow"
sidebar_label: "Apache Kafka/Confluent"
description: "How to produce to and consume from Kafka topics using the Airflow Kafka provider"
id: airflow-kafka
sidebar_custom_props: { icon: 'img/integrations/kafka.png' }
---

MLflow is a commonly used tool for tracking and managing machine learning models. It can be used together with Airflow to orchestrate ML Ops leveraging both tools for what they do best. In this tutorial, you’ll learn how you can use the MLFlow provider in Airflow to manage model life cycles. There are many different use cases you can implement with MLFlow and Airflow, but in this tutorial we’ll focus on getting MLflow experiments ready for production.

## Time to complete

This tutorial takes approximately 30 minutes to complete.

## Assumed knowledge

To get the most out of this tutorial, make sure you have an understanding of:

- The basics of MLflow. See [MLFlow Concepts](https://mlflow.org/docs/latest/concepts.html).
- Airflow fundamentals, such as writing DAGs and defining tasks. See [Get started with Apache Airflow](get-started-with-airflow.md).
- Airflow operators. See [Operators 101](what-is-an-operator.md).
- Airflow connections. See [Managing your Connections in Apache Airflow](connections.md).

## Prerequisites

- The [Astro CLI](https://docs.astronomer.io/astro/cli/get-started).
- Prereq here for MLFlow - experiment already tracked? How to include that if running MLFlow from CLI?

## Step 1: Configure your Astro project


## Step 2: Create your Airflow connections

## Step 3: Create your DAG

## Step 4: Run your DAG